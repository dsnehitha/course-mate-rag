{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import hashlib\n",
    "import pickle\n",
    "import time\n",
    "import ollama\n",
    "from ollama import chat\n",
    "from ollama import Client\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain_qdrant import Qdrant\n",
    "from qdrant_client.http import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./course_materials\"\n",
    "METADATA_DIR = \"./course_materials_metadata\"\n",
    "METADATA_FILE = os.path.join(METADATA_DIR, \"metadata.pkl\")\n",
    "COLLECTION_NAME = \"student_coursework\"\n",
    "QDRANT_URL = \"http://localhost:6333\"\n",
    "\n",
    "os.makedirs(METADATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = None\n",
    "chunks = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6p/lkqygpj57xvfgwp7f108q9000000gn/T/ipykernel_71745/3854982516.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={\"device\": device})\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={\"device\": device})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_client = Client(\n",
    "    host='http://localhost:1134', \n",
    "    headers={'x-some-header':'some-value'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_client = QdrantClient(url=QDRANT_URL, prefer_grpc=False)\n",
    "\n",
    "# docker run -p 6333:6333 -p 6334:6334 \\\n",
    "#     -v \"$(pwd)/qdrant_storage:/qdrant/storage:z\" \\\n",
    "#     qdrant/qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6p/lkqygpj57xvfgwp7f108q9000000gn/T/ipykernel_71745/2155670220.py:1: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.1.2 and will be removed in 0.5.0. Use :class:`~QdrantVectorStore` instead.\n",
      "  vectore_store = Qdrant(\n"
     ]
    }
   ],
   "source": [
    "vectore_store = Qdrant(\n",
    "    client = q_client,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    embeddings=embedding_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pdf_hash():\n",
    "    hasher = hashlib.sha256()\n",
    "    pdf_files = sorted([f for f in os.listdir(DATA_DIR) if f.endswith('.pdf')])\n",
    "\n",
    "    for pdf in pdf_files:\n",
    "        with open(os.path.join(DATA_DIR, pdf), 'rb') as f:\n",
    "            hasher.update(f.read())\n",
    "    return hasher.hexdigest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_db_outdated():\n",
    "    if not os.path.exists(METADATA_FILE):\n",
    "        return True\n",
    "    \n",
    "    try:\n",
    "        with open(METADATA_FILE, 'rb') as f:\n",
    "            saved_hash = pickle.load(f).get(\"pdf_hash\", None)\n",
    "\n",
    "        current_hash = compute_pdf_hash()\n",
    "\n",
    "        return saved_hash != current_hash\n",
    "    \n",
    "    except Exception as e:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_collection():\n",
    "    global index, chunks\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if not is_db_outdated():\n",
    "        print(\"Database is up to date.\")\n",
    "        return\n",
    "    \n",
    "    print(\"Building new collection...\")\n",
    "\n",
    "    loader = DirectoryLoader(DATA_DIR, glob=\"**/*.pdf\", loader_cls=PyPDFLoader, use_multithreading=True)\n",
    "    documents = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "    print(f\"{len(chunks)} text chunks extracted.\")\n",
    "\n",
    "    existing_collections = [col.name for col in q_client.get_collections().collections]\n",
    "\n",
    "    if COLLECTION_NAME in existing_collections:\n",
    "        q_client.update_collection(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            optimizers_config=models.OptimizersConfigDiff(indexing_threshold=10000),\n",
    "        )\n",
    "    else:\n",
    "        q_client.create_collection(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            vectors_config=models.VectorParams(size=384, distance=models.Distance.COSINE),\n",
    "        )\n",
    "    \n",
    "    vectore_store.add_documents(chunks)\n",
    "\n",
    "    with open(METADATA_FILE, 'wb') as f:\n",
    "        pickle.dump({\"pdf_hash\": compute_pdf_hash()}, f)\n",
    "        \n",
    "    print(f\"Collection {COLLECTION_NAME} built in {time.time() - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def contains_img_tags(context: str) -> bool:\n",
    "    \"\"\"Check if the context contains <IMG src> and <IMG> tags.\"\"\"\n",
    "    tags = [\"<IMG src\", \"<IMG>\"]\n",
    "    return all(tag in context for tag in tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query):\n",
    "    results = vectore_store.similarity_search(query, k=5)\n",
    "\n",
    "    context = \"\\n\".join([doc.page_content for doc in results])\n",
    "\n",
    "    print(\"Context for the query:\", context)\n",
    "\n",
    "    print(\"Contains images in the context\", contains_img_tags(context))\n",
    "\n",
    "    prompt = f\"use the provided course material to answer the question: {query}\\n\\nContext:\\n{context}\\n\\nAnswer:\"\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3.2\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ])\n",
    "    \n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    build_collection()\n",
    "\n",
    "    while True:\n",
    "        query = input(\"Enter your question (or 'exit' to quit): \")\n",
    "        if query.lower() == 'exit':\n",
    "            break\n",
    "\n",
    "        start_time = time.time()\n",
    "        print(\"Processing query...\")\n",
    "\n",
    "        answer = generate_answer(query)\n",
    "        print(\"\\nAnswer:\\n\", answer)\n",
    "\n",
    "        print(f\"Query processed in {time.time() - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database is up to date.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing query...\n",
      "Context for the query: 48 2 • Early Humans\n",
      "Access for free at openstax.org\n",
      "48 2 • Early Humans\n",
      "Access for free at openstax.org\n",
      "was once believed the images were designed to be popularly admired as interesting decorations, not unlike the\n",
      "2.1 • Early Human Evolution and Migration 47\n",
      "was once believed the images were designed to be popularly admired as interesting decorations, not unlike the\n",
      "2.1 • Early Human Evolution and Migration 47\n",
      "exchange was vital for cooperation. But did they also have a type of written communication? Some researchers\n",
      "think it’s possible that seemingly abstract signs preserved in caves represent just that. Watch this short video\n",
      "about fascinating scholarship around these intriguing cave signs (https://openstax.org/l/77CaveSigns) to learn\n",
      "more.\n",
      "Ice, Ice, and More Ice\n",
      "Scientists who study the changes that have occurred on Earth over billions of years have identi]ed at least ]ve\n",
      "\n",
      "Answer:\n",
      " Unfortunately, you didn't provide a specific question related to the course material. The text appears to be from two different chapters (2.1 • Early Human Evolution and Migration and Ice, Ice, and More Ice) but doesn't contain a concrete question.\n",
      "\n",
      "If you could provide more context or ask a specific question related to the provided course material, I would be happy to help answer it.\n",
      "Query processed in 5.21 seconds.\n",
      "Processing query...\n",
      "Context for the query: 48 2 • Early Humans\n",
      "Access for free at openstax.org\n",
      "48 2 • Early Humans\n",
      "Access for free at openstax.org\n",
      "was once believed the images were designed to be popularly admired as interesting decorations, not unlike the\n",
      "2.1 • Early Human Evolution and Migration 47\n",
      "was once believed the images were designed to be popularly admired as interesting decorations, not unlike the\n",
      "2.1 • Early Human Evolution and Migration 47\n",
      "exchange was vital for cooperation. But did they also have a type of written communication? Some researchers\n",
      "think it’s possible that seemingly abstract signs preserved in caves represent just that. Watch this short video\n",
      "about fascinating scholarship around these intriguing cave signs (https://openstax.org/l/77CaveSigns) to learn\n",
      "more.\n",
      "Ice, Ice, and More Ice\n",
      "Scientists who study the changes that have occurred on Earth over billions of years have identi]ed at least ]ve\n",
      "\n",
      "Answer:\n",
      " I'm happy to help you with the question! However, I don't see a specific question provided. Could you please provide the actual question from the course material \"48 2 • Early Humans\" by OpenStax?\n",
      "\n",
      "If you'd like, I can try to answer based on the context provided:\n",
      "\n",
      "\"was once believed the images were designed to be popularly admired as interesting decorations, not unlike the [...]\" \n",
      "\n",
      "It seems that this is a statement about early human images being used for decoration purposes.\n",
      "Query processed in 2.20 seconds.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Converting everything into single modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "image_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_from_pdfs():\n",
    "    if not os.path.exists(\"extracted_images\"):\n",
    "        os.makedirs(\"extracted_images\")\n",
    "        \n",
    "    for file_name in os.listdir(DATA_DIR):\n",
    "        file_path = os.path.join(DATA_DIR, file_name)\n",
    "        \n",
    "        if os.path.isfile(file_path) and file_name.endswith('.pdf'):\n",
    "            print(f\"Processing {file_name}...\")\n",
    "\n",
    "            with pymupdf.open(file_path) as doc:\n",
    "                if not os.path.exists(\"extracted_images\"):\n",
    "                    os.makedirs(\"extracted_images\")\n",
    "                \n",
    "            #loop through all documents and all pages\n",
    "                for page_num in range(len(doc)):\n",
    "                    page = doc[page_num]\n",
    "\n",
    "                    text = page.get_text().strip()\n",
    "                    text_data.append({\"response\": text, \"name\": page_num+1})\n",
    "\n",
    "                    images = page.get_images(full=True)\n",
    "                    \n",
    "                    # Extract images\n",
    "                    for img_index, img in enumerate(images, start=0):\n",
    "                        xref = img[0]\n",
    "                        base_image = doc.extract_image(xref)\n",
    "                        image_bytes = base_image[\"image\"]\n",
    "                        image_ext = base_image[\"ext\"]\n",
    "\n",
    "                        image_filename = f\"extracted_images/page_{page_num + 1}_img_{img_index + 1}.{image_ext}\"\n",
    "                        \n",
    "                        # with open(image_filename, \"wb\") as img_file:\n",
    "                        #     img_file.write(image_bytes)\n",
    "\n",
    "                        # image_data.append(image_filename)\n",
    "\n",
    "                        image = Image.open(io.BytesIO(image_bytes))\n",
    "                        image.save(image_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Apollo 11 - Wikipedia.pdf...\n"
     ]
    }
   ],
   "source": [
    "extract_images_from_pdfs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image captioning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted_images_2/page_10_img_1.jpeg\n",
      "model='llama3.2-vision' created_at='2025-04-17T15:42:17.324808Z' done=True done_reason='stop' total_duration=20954653916 load_duration=35406208 prompt_eval_count=63 prompt_eval_duration=3810827333 eval_count=238 eval_duration=17018100375 message=Message(role='assistant', content='<IMG src=extracted_images_2/page_10_img_1.jpeg>The image depicts a person in a white spacesuit inside a spacecraft, with their back against the wall and their head facing towards the camera. The suit appears to be made of a thick, white material, possibly Kevlar or other synthetic fibers.\\n\\n*   **Spacesuit:**\\n    *   Color: White\\n    *   Material: Thick, possibly Kevlar or synthetic fibers\\n    *   Purpose: Likely for spacewalks or extravehicular activities\\n*   **Spacecraft Interior:**\\n    *   Background: Gray or metallic color\\n    *   Lighting: Possibly fluorescent or LED lights\\n    *   Equipment: Various instruments and controls visible on the walls and ceiling\\n    *   Purpose: For space travel, exploration, or scientific research\\n\\nThe image suggests that the person is preparing for a spacewalk or extravehicular activity, given their attire and position against the wall. The spacecraft interior provides a functional environment for astronauts to conduct various tasks, including scientific experiments, maintenance, and repairs.\\n\\nOverall, the image conveys a sense of professionalism and preparedness for space exploration, highlighting the importance of specialized equipment and protective gear in this field.<IMG>', images=None, tool_calls=None)\n",
      "extracted_images_2/page_9_img_1.png\n",
      "model='llama3.2-vision' created_at='2025-04-17T15:42:34.863985Z' done=True done_reason='stop' total_duration=17525126375 load_duration=21690708 prompt_eval_count=63 prompt_eval_duration=1705269333 eval_count=217 eval_duration=15725584417 message=Message(role='assistant', content=\"<IMG src=extracted_images_2/page_9_img_1.png>The image presents a circular logo featuring an eagle perched on top of the moon, with Earth visible in the background. The logo is set against a black background and incorporates various colors, including blue, yellow, white, brown, and gray.\\n\\n*   **Logo Description:**\\n    *   Circular shape\\n    *   Eagle perched on the moon\\n    *   Earth visible in the background\\n    *   Black background\\n    *   Incorporates multiple colors (blue, yellow, white, brown, gray)\\n*   **Mission Name:**\\n    *   Apollo 11\\n*   **Mission Type:**\\n    *   Space Mission\\n*   **Launch Date:**\\n    *   July 16, 1969\\n\\nThe logo effectively conveys the mission's focus on space exploration and its connection to Earth. The use of a circular shape and multiple colors adds visual appeal, while the eagle and moon imagery evoke a sense of grandeur and adventure. Overall, the logo is a fitting representation of the Apollo 11 mission's historic significance and accomplishments.<IMG>\", images=None, tool_calls=None)\n",
      "extracted_images_2/page_3_img_2.jpeg\n",
      "model='llama3.2-vision' created_at='2025-04-17T15:43:00.941115Z' done=True done_reason='stop' total_duration=26065787458 load_duration=20129958 prompt_eval_count=63 prompt_eval_duration=1177819333 eval_count=297 eval_duration=24802107042 message=Message(role='assistant', content='<IMG src=extracted_images_2/page_3_img_2.jpeg>The image shows three astronauts in front of a large moon in their spacesuits.\\n\\n*   The astronaut on the left has short dark hair and is wearing a white NASA logo on his right chest.\\n    *   He has a blue patch with \"NASA\" written across it, an American flag patch on his left arm, and a round black device attached to his suit near his waist. \\n    *   He stands with his hands clasped in front of him at about mid-thigh height.\\n*   The astronaut in the middle is taller than the other two and has short dark hair.\\n    *   His white spacesuit has an American flag patch on his right arm, a round blue device attached to his suit near his waist, and a blue patch with \"NASA\" written across it on his left chest. \\n    *   He stands in front of the other two astronauts with his hands clasped at about mid-thigh height.\\n*   The astronaut on the right has short dark hair and is wearing an American flag patch on his left arm and a blue patch with \"NASA\" written across it on his right chest.\\n    *   His white spacesuit has a round black device attached to his suit near his waist, and he stands with his hands clasped at about mid-thigh height.\\n\\nThe background of the image is a large moon that appears grey and rocky. The astronauts are standing in front of it, creating an illusion of them being on the moon itself.<IMG>', images=None, tool_calls=None)\n",
      "extracted_images_2/page_3_img_1.png\n",
      "model='llama3.2-vision' created_at='2025-04-17T15:44:44.924395Z' done=True done_reason='stop' total_duration=103901310250 load_duration=31226208 prompt_eval_count=63 prompt_eval_duration=83917921125 eval_count=273 eval_duration=19864717000 message=Message(role='assistant', content='<IMG src=extracted_images_2/page_3_img_1.png>The image presents a circular emblem featuring the Apollo 11 mission logo, accompanied by a small section of text at the bottom.\\n\\n*   **Emblem:**\\n    *   The emblem is centered in the image and features a black background with a thin blue border.\\n    *   At the top of the emblem, the words \"APOLLO 11\" are written in gold letters.\\n    *   Below the text, an illustration of an eagle grasping a branch in its talons is depicted.\\n    *   The eagle\\'s head is turned to the right, and its wings are spread outwards.\\n    *   In the background, a small portion of the Earth is visible above the eagle\\'s wing.\\n*   **Text Section:**\\n    *   Below the emblem, there is a small section of text that reads \"JULY 1969\" in black letters.\\n    *   The text is positioned at the bottom center of the image.\\n\\nIn summary, the image showcases the Apollo 11 mission logo, which features an eagle and the words \"APOLLO 11\" in gold letters. The logo is surrounded by a blue border and set against a black background, with a small portion of the Earth visible above the eagle\\'s wing. Below the emblem, there is a text section that reads \"JULY 1969\".<IMG>', images=None, tool_calls=None)\n",
      "extracted_images_2/page_8_img_1.jpeg\n",
      "model='llama3.2-vision' created_at='2025-04-17T15:46:13.624364Z' done=True done_reason='stop' total_duration=88593059125 load_duration=41888583 prompt_eval_count=63 prompt_eval_duration=76724958250 eval_count=162 eval_duration=11652042125 message=Message(role='assistant', content=\"<IMG src=extracted_images_2/page_8_img_1.jpeg>The image depicts a group of men in a control room, likely during the Apollo 11 mission. The man on the left is wearing a white shirt with thin stripes and a tie, while the man in the middle has his hand raised to his chin, wearing a watch on his wrist. The man on the right is also wearing a white shirt.\\n\\nThe men are seated at a desk or console, surrounded by various pieces of equipment and monitors. The atmosphere appears tense but focused, with the men intently monitoring their screens and equipment. The image suggests that they are engaged in a critical task, possibly related to the Apollo 11 mission's launch or navigation.\\n\\nOverall, the image captures a moment of intense focus and concentration among the control room personnel as they work together to ensure the success of the mission.<IMG>\", images=None, tool_calls=None)\n",
      "extracted_images_2/page_5_img_1.jpeg\n",
      "model='llama3.2-vision' created_at='2025-04-17T15:47:37.288215Z' done=True done_reason='stop' total_duration=83599149708 load_duration=32088042 prompt_eval_count=63 prompt_eval_duration=73518772250 eval_count=139 eval_duration=9952438041 message=Message(role='assistant', content='<IMG src=extracted_images_2/page_5_img_1.jpeg>The image depicts John F. Kennedy, the 35th President of the United States, standing at a podium with two microphones. The background appears to be an outdoor setting, possibly a stadium or arena, with bleachers visible behind him.\\n\\nHere are some key points about the image:\\n\\n* **President:** John F. Kennedy\\n* **Podium:** Wooden podium with two microphones\\n* **Background:** Outdoor setting, possibly a stadium or arena\\n\\t+ Bleachers: Visible behind Kennedy\\n\\nIn summary, the image shows President John F. Kennedy standing at a podium with two microphones in an outdoor setting, likely a stadium or arena, with bleachers visible behind him.<IMG>', images=None, tool_calls=None)\n",
      "extracted_images_2/page_10_img_3.jpeg\n",
      "model='llama3.2-vision' created_at='2025-04-17T15:49:01.889439Z' done=True done_reason='stop' total_duration=84560043875 load_duration=27300459 prompt_eval_count=63 prompt_eval_duration=73052645250 eval_count=157 eval_duration=11332447375 message=Message(role='assistant', content=\"<IMG src=extracted_images_2/page_10_img_3.jpeg>The image presents a map of the Moon's surface, featuring the Apollo 11 landing site. The map is rendered in grayscale, with various markings and labels indicating different geographical features.\\n\\n*   **Map Features:**\\n    *   Grayscale color scheme\\n    *   Various markings and labels for geographical features\\n*   **Apollo 11 Landing Site:**\\n    *   Marked on the map with a distinct symbol or label\\n    *   Located in the center of the image, near the equator\\n*   **Background:**\\n    *   Solid gray color\\n\\nIn summary, the image displays a detailed map of the Moon's surface, highlighting the Apollo 11 landing site. The map's grayscale color scheme and various markings provide valuable information about the lunar terrain.<IMG>\", images=None, tool_calls=None)\n",
      "extracted_images_2/page_1_img_1.jpeg\n",
      "model='llama3.2-vision' created_at='2025-04-17T15:50:22.304273Z' done=True done_reason='stop' total_duration=80361032417 load_duration=35390875 prompt_eval_count=63 prompt_eval_duration=71761275792 eval_count=119 eval_duration=8384378416 message=Message(role='assistant', content=\"<IMG src=extracted_images_2/page_1_img_1.jpeg>The image depicts an astronaut in a white spacesuit standing on the moon's surface, with their shadow cast behind them. The astronaut is wearing a helmet and appears to be in motion.\\n\\n*   **Astronaut**\\n    *   Wearing a white spacesuit\\n    *   Helmet visible\\n    *   Appears to be in motion\\n*   **Moon's Surface**\\n    *   Rocky terrain\\n    *   No vegetation or other features visible\\n\\nThe image suggests that the astronaut is on a mission to explore the moon's surface, possibly as part of a NASA space program.<IMG>\", images=None, tool_calls=None)\n",
      "extracted_images_2/page_10_img_2.jpeg\n",
      "model='llama3.2-vision' created_at='2025-04-17T15:51:54.159054Z' done=True done_reason='stop' total_duration=91815139083 load_duration=22648208 prompt_eval_count=63 prompt_eval_duration=74843363750 eval_count=226 eval_duration=16801135750 message=Message(role='assistant', content='<IMG src=extracted_images_2/page_10_img_2.jpeg>The image depicts a commemorative coin from the Apollo 11 mission, which successfully landed on the moon in July 1969. The coin features an embossed design with several key details:\\n\\n* **Design Elements:**\\n\\t+ An eagle\\'s head and wings on one side\\n\\t+ A banner with the words \"APOLLO 11\" at the top\\n\\t+ The year \"1969\" at the bottom\\n\\n**Key Features**\\n\\n* **Mission Details:** The coin commemorates the Apollo 11 mission, which was launched on July 16, 1969.\\n* **Landing Date:** The coin indicates that the spacecraft landed on the moon on July 20, 1969.\\n* **Return Date:** The coin also notes that the spacecraft returned to Earth on July 24, 1969.\\n\\n**Historical Significance**\\n\\nThe Apollo 11 mission was a groundbreaking achievement in space exploration, marking the first time humans had set foot on another celestial body. This coin serves as a symbol of this historic event and a reminder of the incredible feats accomplished by NASA\\'s astronauts during the Apollo program.<IMG>', images=None, tool_calls=None)\n",
      "extracted_images_2/page_1_img_2.png\n",
      "model='llama3.2-vision' created_at='2025-04-17T15:53:20.154859Z' done=True done_reason='stop' total_duration=85958518791 load_duration=35578833 prompt_eval_count=63 prompt_eval_duration=76051507333 eval_count=134 eval_duration=9714673500 message=Message(role='assistant', content='<IMG src=extracted_images_2/page_1_img_2.png>The image shows a Wikipedia logo made up of puzzle pieces. The logo is white with black letters and symbols on it, including the Greek letter omega (Ω), the Roman numeral I (I), the symbol for infinity (∞), and others.\\n\\n*   The logo is composed of interlocking puzzle pieces that fit together to form a sphere.\\n*   The puzzle pieces are arranged in a way that creates a sense of movement and fluidity.\\n*   The logo is set against a plain white background, which helps it stand out and makes it more visible.\\n\\nOverall, the Wikipedia logo is a clever and effective design that effectively conveys the idea of collaboration and community.<IMG>', images=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "#llama vision\n",
    "for img in os.listdir(\"extracted_images_2\"):\n",
    "    # image = Image.open(f\"extracted_images/{img}\")\n",
    "    print(f\"extracted_images_2/{img}\")\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model='llama3.2-vision',\n",
    "        messages=[{\n",
    "            'role': 'user',\n",
    "            'content': 'You are an assistant tasked with summarizing tables, images and text NASA website for retrieval. \\\n",
    "                        These summaries will be embedded and used to retrieve the raw text or table elements \\\n",
    "                        Give a concise summary of the table or text that is well optimized for retrieval.',\n",
    "            'images': [f\"extracted_images_2/{img}\"],\n",
    "        }]\n",
    "    )\n",
    "\n",
    "    response.message.content = f\"<IMG src=extracted_images_2/{img}>\" + response.message.content + \"<IMG>\"\n",
    "\n",
    "    print(response)\n",
    "\n",
    "    image_data.append({\"response\": response, \"name\": img})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_image_captions():\n",
    "#     global text_data, image_data\n",
    "\n",
    "#     for img in os.listdir(IMAGE_DIR):\n",
    "#         img_path = os.path.join(IMAGE_DIR, img)\n",
    "#         start_time = time.time()\n",
    "\n",
    "#         if os.path.isfile(img_path):\n",
    "#             print(f\"\\nGenerating caption for {img}...\\n\")\n",
    "\n",
    "#             response = chat(\n",
    "#                 model=\"llama3.2-vision\",\n",
    "#                 messages=[\n",
    "#                     {\n",
    "#                         \"role\": \"system\",\n",
    "#                         \"content\": \"You are a helpful assistant that generates captions for images.\"\n",
    "#                     },\n",
    "#                     {\n",
    "#                         \"role\": \"user\",\n",
    "#                         \"content\": \"You are an assistant tasked with summarizing tables, images and text NASA website for retrieval. \\\n",
    "#                                     These summaries will be embedded and used to retrieve the raw text or table elements \\\n",
    "#                                     Give a concise summary of the table or text that is well optimized for retrieval.\",\n",
    "#                         \"images\": [f\"{IMAGE_DIR}/{img}\"],\n",
    "#                     }\n",
    "#                 ],\n",
    "#             )\n",
    "\n",
    "#             response.message.content = f\"<IMG src=extracted_images/{img}>\" + response.message.content + \"<IMG>\"\n",
    "#             image_data.append({\"response\": response, \"name\": img})\n",
    "\n",
    "#     doc_list = [Document(page_content=text['response'], metadata={\"name\": text['name']}) for text in text_data]\n",
    "#     img_list = [Document(page_content=img['response'].message['content'], metadata={\"name\": img['name']}) for img in image_data]\n",
    "#     print(img_list)\n",
    "#     print(f\"Generated image captions in {time.time() - start_time:.2f} seconds.\\n\")\n",
    "        \n",
    "#     return doc_list, img_list       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'response': ChatResponse(model='llama3.2-vision', created_at='2025-04-17T15:34:11.556089Z', done=True, done_reason='stop', total_duration=94277953750, load_duration=5931930542, prompt_eval_count=106, prompt_eval_duration=74189990000, eval_count=195, eval_duration=14058777125, message=Message(role='assistant', content=\"The image shows a person in a white spacesuit floating inside an aircraft, with various instruments and controls visible on the walls and ceiling.\\n\\n* A person in a white spacesuit is floating inside an aircraft.\\n\\t+ The person appears to be a pilot or astronaut, judging by their attire and position within the cockpit.\\n\\t+ They are wearing a white spacesuit with a helmet and gloves, indicating that they are prepared for space travel.\\n* Various instruments and controls are visible on the walls and ceiling of the aircraft.\\n\\t+ The instruments appear to be electronic devices, possibly monitoring the aircraft's systems or displaying information to the pilot.\\n\\t+ The controls seem to be manual levers or buttons, used by the pilot to navigate the aircraft.\\n\\nOverall, the image suggests that the person is preparing for a space mission and is utilizing the aircraft as a means of transportation. The presence of various instruments and controls implies that the aircraft is equipped with advanced technology to support the mission.\", images=None, tool_calls=None)),\n",
       "  'name': 'page_10_img_1.jpeg'},\n",
       " {'response': ChatResponse(model='llama3.2-vision', created_at='2025-04-17T15:35:59.805723Z', done=True, done_reason='stop', total_duration=20357999542, load_duration=110367584, prompt_eval_count=99, prompt_eval_duration=10522524583, eval_count=132, eval_duration=9636915667, message=Message(role='assistant', content='The provided image appears to be an interior view of a spacecraft, likely taken during a space mission.\\n\\n* The image features a large, cylindrical object with a rounded top and bottom.\\n\\t+ The object is made of metal or some other reflective material.\\n\\t+ There are several small, round windows or portholes along the sides of the object.\\n* A person in a white spacesuit is visible inside the object.\\n\\t+ The person is standing near one of the windows.\\n\\t+ They appear to be looking out at something outside the spacecraft.\\n\\nThe image suggests that the spacecraft has been equipped with advanced technology and instrumentation for conducting scientific experiments or observations.', images=None, tool_calls=None)),\n",
       "  'name': 'page_10_img_1.jpeg'},\n",
       " {'response': ChatResponse(model='llama3.2-vision', created_at='2025-04-17T15:36:28.451067Z', done=True, done_reason='stop', total_duration=28608568333, load_duration=37896833, prompt_eval_count=99, prompt_eval_duration=5886528125, eval_count=312, eval_duration=22565502666, message=Message(role='assistant', content='The image depicts the Apollo 11 mission patch, which was used to identify the crew members of the first manned mission to land on the Moon in July 1969.\\n\\n*   **Mission Name and Crew**\\n    *   The mission name \"Apollo 11\" is prominently displayed at the top of the patch.\\n    *   The crew members are not explicitly listed in this section, but they can be inferred from other sources as being Neil Armstrong, Edwin \"Buzz\" Aldrin, Michael Collins, and Richard Gordon.\\n*   **Eagle Lunar Module**\\n    *   A stylized illustration of the Eagle lunar module is featured in the center of the patch.\\n    *   The Eagle was the first spacecraft to land on the Moon\\'s surface during the Apollo 11 mission.\\n*   **Earth**\\n    *   A small, blue-and-white image of Earth is visible above the Eagle lunar module.\\n    *   This represents the astronauts\\' perspective from space, looking back at their home planet.\\n*   **Moon Surface**\\n    *   The moon\\'s surface is depicted in shades of gray and white, with craters and other geological features visible.\\n    *   This section of the patch serves as a reminder of the historic achievement of landing on another celestial body.\\n\\nIn summary, the Apollo 11 mission patch is a symbolic representation of the first manned mission to land on the Moon. It features the mission name, crew members\\' names (although not explicitly listed), and iconic images of the Eagle lunar module, Earth, and the moon\\'s surface.', images=None, tool_calls=None)),\n",
       "  'name': 'page_9_img_1.png'},\n",
       " {'response': ChatResponse(model='llama3.2-vision', created_at='2025-04-17T15:42:17.324808Z', done=True, done_reason='stop', total_duration=20954653916, load_duration=35406208, prompt_eval_count=63, prompt_eval_duration=3810827333, eval_count=238, eval_duration=17018100375, message=Message(role='assistant', content='<IMG src=extracted_images_2/page_10_img_1.jpeg>The image depicts a person in a white spacesuit inside a spacecraft, with their back against the wall and their head facing towards the camera. The suit appears to be made of a thick, white material, possibly Kevlar or other synthetic fibers.\\n\\n*   **Spacesuit:**\\n    *   Color: White\\n    *   Material: Thick, possibly Kevlar or synthetic fibers\\n    *   Purpose: Likely for spacewalks or extravehicular activities\\n*   **Spacecraft Interior:**\\n    *   Background: Gray or metallic color\\n    *   Lighting: Possibly fluorescent or LED lights\\n    *   Equipment: Various instruments and controls visible on the walls and ceiling\\n    *   Purpose: For space travel, exploration, or scientific research\\n\\nThe image suggests that the person is preparing for a spacewalk or extravehicular activity, given their attire and position against the wall. The spacecraft interior provides a functional environment for astronauts to conduct various tasks, including scientific experiments, maintenance, and repairs.\\n\\nOverall, the image conveys a sense of professionalism and preparedness for space exploration, highlighting the importance of specialized equipment and protective gear in this field.<IMG>', images=None, tool_calls=None)),\n",
       "  'name': 'page_10_img_1.jpeg'},\n",
       " {'response': ChatResponse(model='llama3.2-vision', created_at='2025-04-17T15:42:34.863985Z', done=True, done_reason='stop', total_duration=17525126375, load_duration=21690708, prompt_eval_count=63, prompt_eval_duration=1705269333, eval_count=217, eval_duration=15725584417, message=Message(role='assistant', content=\"<IMG src=extracted_images_2/page_9_img_1.png>The image presents a circular logo featuring an eagle perched on top of the moon, with Earth visible in the background. The logo is set against a black background and incorporates various colors, including blue, yellow, white, brown, and gray.\\n\\n*   **Logo Description:**\\n    *   Circular shape\\n    *   Eagle perched on the moon\\n    *   Earth visible in the background\\n    *   Black background\\n    *   Incorporates multiple colors (blue, yellow, white, brown, gray)\\n*   **Mission Name:**\\n    *   Apollo 11\\n*   **Mission Type:**\\n    *   Space Mission\\n*   **Launch Date:**\\n    *   July 16, 1969\\n\\nThe logo effectively conveys the mission's focus on space exploration and its connection to Earth. The use of a circular shape and multiple colors adds visual appeal, while the eagle and moon imagery evoke a sense of grandeur and adventure. Overall, the logo is a fitting representation of the Apollo 11 mission's historic significance and accomplishments.<IMG>\", images=None, tool_calls=None)),\n",
       "  'name': 'page_9_img_1.png'},\n",
       " {'response': ChatResponse(model='llama3.2-vision', created_at='2025-04-17T15:43:00.941115Z', done=True, done_reason='stop', total_duration=26065787458, load_duration=20129958, prompt_eval_count=63, prompt_eval_duration=1177819333, eval_count=297, eval_duration=24802107042, message=Message(role='assistant', content='<IMG src=extracted_images_2/page_3_img_2.jpeg>The image shows three astronauts in front of a large moon in their spacesuits.\\n\\n*   The astronaut on the left has short dark hair and is wearing a white NASA logo on his right chest.\\n    *   He has a blue patch with \"NASA\" written across it, an American flag patch on his left arm, and a round black device attached to his suit near his waist. \\n    *   He stands with his hands clasped in front of him at about mid-thigh height.\\n*   The astronaut in the middle is taller than the other two and has short dark hair.\\n    *   His white spacesuit has an American flag patch on his right arm, a round blue device attached to his suit near his waist, and a blue patch with \"NASA\" written across it on his left chest. \\n    *   He stands in front of the other two astronauts with his hands clasped at about mid-thigh height.\\n*   The astronaut on the right has short dark hair and is wearing an American flag patch on his left arm and a blue patch with \"NASA\" written across it on his right chest.\\n    *   His white spacesuit has a round black device attached to his suit near his waist, and he stands with his hands clasped at about mid-thigh height.\\n\\nThe background of the image is a large moon that appears grey and rocky. The astronauts are standing in front of it, creating an illusion of them being on the moon itself.<IMG>', images=None, tool_calls=None)),\n",
       "  'name': 'page_3_img_2.jpeg'},\n",
       " {'response': ChatResponse(model='llama3.2-vision', created_at='2025-04-17T15:44:44.924395Z', done=True, done_reason='stop', total_duration=103901310250, load_duration=31226208, prompt_eval_count=63, prompt_eval_duration=83917921125, eval_count=273, eval_duration=19864717000, message=Message(role='assistant', content='<IMG src=extracted_images_2/page_3_img_1.png>The image presents a circular emblem featuring the Apollo 11 mission logo, accompanied by a small section of text at the bottom.\\n\\n*   **Emblem:**\\n    *   The emblem is centered in the image and features a black background with a thin blue border.\\n    *   At the top of the emblem, the words \"APOLLO 11\" are written in gold letters.\\n    *   Below the text, an illustration of an eagle grasping a branch in its talons is depicted.\\n    *   The eagle\\'s head is turned to the right, and its wings are spread outwards.\\n    *   In the background, a small portion of the Earth is visible above the eagle\\'s wing.\\n*   **Text Section:**\\n    *   Below the emblem, there is a small section of text that reads \"JULY 1969\" in black letters.\\n    *   The text is positioned at the bottom center of the image.\\n\\nIn summary, the image showcases the Apollo 11 mission logo, which features an eagle and the words \"APOLLO 11\" in gold letters. The logo is surrounded by a blue border and set against a black background, with a small portion of the Earth visible above the eagle\\'s wing. Below the emblem, there is a text section that reads \"JULY 1969\".<IMG>', images=None, tool_calls=None)),\n",
       "  'name': 'page_3_img_1.png'},\n",
       " {'response': ChatResponse(model='llama3.2-vision', created_at='2025-04-17T15:46:13.624364Z', done=True, done_reason='stop', total_duration=88593059125, load_duration=41888583, prompt_eval_count=63, prompt_eval_duration=76724958250, eval_count=162, eval_duration=11652042125, message=Message(role='assistant', content=\"<IMG src=extracted_images_2/page_8_img_1.jpeg>The image depicts a group of men in a control room, likely during the Apollo 11 mission. The man on the left is wearing a white shirt with thin stripes and a tie, while the man in the middle has his hand raised to his chin, wearing a watch on his wrist. The man on the right is also wearing a white shirt.\\n\\nThe men are seated at a desk or console, surrounded by various pieces of equipment and monitors. The atmosphere appears tense but focused, with the men intently monitoring their screens and equipment. The image suggests that they are engaged in a critical task, possibly related to the Apollo 11 mission's launch or navigation.\\n\\nOverall, the image captures a moment of intense focus and concentration among the control room personnel as they work together to ensure the success of the mission.<IMG>\", images=None, tool_calls=None)),\n",
       "  'name': 'page_8_img_1.jpeg'},\n",
       " {'response': ChatResponse(model='llama3.2-vision', created_at='2025-04-17T15:47:37.288215Z', done=True, done_reason='stop', total_duration=83599149708, load_duration=32088042, prompt_eval_count=63, prompt_eval_duration=73518772250, eval_count=139, eval_duration=9952438041, message=Message(role='assistant', content='<IMG src=extracted_images_2/page_5_img_1.jpeg>The image depicts John F. Kennedy, the 35th President of the United States, standing at a podium with two microphones. The background appears to be an outdoor setting, possibly a stadium or arena, with bleachers visible behind him.\\n\\nHere are some key points about the image:\\n\\n* **President:** John F. Kennedy\\n* **Podium:** Wooden podium with two microphones\\n* **Background:** Outdoor setting, possibly a stadium or arena\\n\\t+ Bleachers: Visible behind Kennedy\\n\\nIn summary, the image shows President John F. Kennedy standing at a podium with two microphones in an outdoor setting, likely a stadium or arena, with bleachers visible behind him.<IMG>', images=None, tool_calls=None)),\n",
       "  'name': 'page_5_img_1.jpeg'},\n",
       " {'response': ChatResponse(model='llama3.2-vision', created_at='2025-04-17T15:49:01.889439Z', done=True, done_reason='stop', total_duration=84560043875, load_duration=27300459, prompt_eval_count=63, prompt_eval_duration=73052645250, eval_count=157, eval_duration=11332447375, message=Message(role='assistant', content=\"<IMG src=extracted_images_2/page_10_img_3.jpeg>The image presents a map of the Moon's surface, featuring the Apollo 11 landing site. The map is rendered in grayscale, with various markings and labels indicating different geographical features.\\n\\n*   **Map Features:**\\n    *   Grayscale color scheme\\n    *   Various markings and labels for geographical features\\n*   **Apollo 11 Landing Site:**\\n    *   Marked on the map with a distinct symbol or label\\n    *   Located in the center of the image, near the equator\\n*   **Background:**\\n    *   Solid gray color\\n\\nIn summary, the image displays a detailed map of the Moon's surface, highlighting the Apollo 11 landing site. The map's grayscale color scheme and various markings provide valuable information about the lunar terrain.<IMG>\", images=None, tool_calls=None)),\n",
       "  'name': 'page_10_img_3.jpeg'},\n",
       " {'response': ChatResponse(model='llama3.2-vision', created_at='2025-04-17T15:50:22.304273Z', done=True, done_reason='stop', total_duration=80361032417, load_duration=35390875, prompt_eval_count=63, prompt_eval_duration=71761275792, eval_count=119, eval_duration=8384378416, message=Message(role='assistant', content=\"<IMG src=extracted_images_2/page_1_img_1.jpeg>The image depicts an astronaut in a white spacesuit standing on the moon's surface, with their shadow cast behind them. The astronaut is wearing a helmet and appears to be in motion.\\n\\n*   **Astronaut**\\n    *   Wearing a white spacesuit\\n    *   Helmet visible\\n    *   Appears to be in motion\\n*   **Moon's Surface**\\n    *   Rocky terrain\\n    *   No vegetation or other features visible\\n\\nThe image suggests that the astronaut is on a mission to explore the moon's surface, possibly as part of a NASA space program.<IMG>\", images=None, tool_calls=None)),\n",
       "  'name': 'page_1_img_1.jpeg'},\n",
       " {'response': ChatResponse(model='llama3.2-vision', created_at='2025-04-17T15:51:54.159054Z', done=True, done_reason='stop', total_duration=91815139083, load_duration=22648208, prompt_eval_count=63, prompt_eval_duration=74843363750, eval_count=226, eval_duration=16801135750, message=Message(role='assistant', content='<IMG src=extracted_images_2/page_10_img_2.jpeg>The image depicts a commemorative coin from the Apollo 11 mission, which successfully landed on the moon in July 1969. The coin features an embossed design with several key details:\\n\\n* **Design Elements:**\\n\\t+ An eagle\\'s head and wings on one side\\n\\t+ A banner with the words \"APOLLO 11\" at the top\\n\\t+ The year \"1969\" at the bottom\\n\\n**Key Features**\\n\\n* **Mission Details:** The coin commemorates the Apollo 11 mission, which was launched on July 16, 1969.\\n* **Landing Date:** The coin indicates that the spacecraft landed on the moon on July 20, 1969.\\n* **Return Date:** The coin also notes that the spacecraft returned to Earth on July 24, 1969.\\n\\n**Historical Significance**\\n\\nThe Apollo 11 mission was a groundbreaking achievement in space exploration, marking the first time humans had set foot on another celestial body. This coin serves as a symbol of this historic event and a reminder of the incredible feats accomplished by NASA\\'s astronauts during the Apollo program.<IMG>', images=None, tool_calls=None)),\n",
       "  'name': 'page_10_img_2.jpeg'},\n",
       " {'response': ChatResponse(model='llama3.2-vision', created_at='2025-04-17T15:53:20.154859Z', done=True, done_reason='stop', total_duration=85958518791, load_duration=35578833, prompt_eval_count=63, prompt_eval_duration=76051507333, eval_count=134, eval_duration=9714673500, message=Message(role='assistant', content='<IMG src=extracted_images_2/page_1_img_2.png>The image shows a Wikipedia logo made up of puzzle pieces. The logo is white with black letters and symbols on it, including the Greek letter omega (Ω), the Roman numeral I (I), the symbol for infinity (∞), and others.\\n\\n*   The logo is composed of interlocking puzzle pieces that fit together to form a sphere.\\n*   The puzzle pieces are arranged in a way that creates a sense of movement and fluidity.\\n*   The logo is set against a plain white background, which helps it stand out and makes it more visible.\\n\\nOverall, the Wikipedia logo is a clever and effective design that effectively conveys the idea of collaboration and community.<IMG>', images=None, tool_calls=None)),\n",
       "  'name': 'page_1_img_2.png'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "docs_list = [Document(page_content=text['response'], metadata={\"name\": text['name']}) for text in text_data]\n",
    "img_list = [Document(page_content=img['response'].message['content'], metadata={\"name\": img['name']}) for img in image_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=400, chunk_overlap=50\n",
    ")\n",
    "\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "img_splits = text_splitter.split_documents(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents and images added to the collection.\n"
     ]
    }
   ],
   "source": [
    "existing_collections = [col.name for col in q_client.get_collections().collections]\n",
    "\n",
    "if COLLECTION_NAME in existing_collections:\n",
    "    q_client.update_collection(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        optimizers_config=models.OptimizersConfigDiff(indexing_threshold=10000),\n",
    "    )\n",
    "else:\n",
    "    q_client.create_collection(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        vectors_config=models.VectorParams(size=384, distance=models.Distance.COSINE),\n",
    "    )\n",
    "\n",
    "documents = doc_splits + img_splits\n",
    "\n",
    "vectore_store.add_documents(documents)\n",
    "\n",
    "print(\"Documents and images added to the collection.\")\n",
    "\n",
    "with open(METADATA_FILE, 'wb') as f:\n",
    "        pickle.dump({\"pdf_hash\": compute_pdf_hash()}, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing query...\n",
      "Context for the query: Apollo 11 insignia\n",
      "The Apollo 11 mission emblem was designed by Collins, who\n",
      "wanted a symbol for \"peaceful lunar landing by the United States\".\n",
      "At Lovell's suggestion, he chose the bald eagle, the national bird of\n",
      "the United States, as the symbol. Tom Wilson, a simulator\n",
      "instructor, suggested an olive branch in its beak to represent their\n",
      "peaceful mission. Collins added a lunar background with the Earth\n",
      "in the distance. The sunlight in the image was coming from the\n",
      "wrong direction; the shadow should have been in the lower part of\n",
      "the Earth instead of the left. Aldrin, Armstrong and Collins\n",
      "decided the Eagle and the Moon would be in their natural colors,\n",
      "and decided on a blue and gold border. Armstrong was concerned\n",
      "that \"eleven\" would not be understood by non-English speakers, so\n",
      "they went with \"Apollo 11\",[70] and they decided not to put their\n",
      "names on the patch, so it would \"be representative of everyone\n",
      "who had worked toward a lunar landing\".[71]\n",
      "An illustrator at the Manned Spacecraft Center (MSC) did the artwork, which was then sent off to\n",
      "NASA officials for approval.[70] The design was rejected. Bob Gilruth, the director of the MSC felt the\n",
      "talons of the eagle looked \"too warlike\".[72] After some discussion, the olive branch was moved to the\n",
      "talons.[72] When the Eisenhower dollar coin was released in 1971, the patch design provided the eagle\n",
      "for its reverse side.[73] The design was also used for the smaller Susan B. Anthony dollar unveiled in\n",
      "1979.[74]\n",
      "After the crew of Apollo 10 named their spacecraft Charlie Brown and Snoopy, assistant manager for\n",
      "public affairs Julian Scheer wrote to George Low, the Manager of the Apollo Spacecraft Program\n",
      "Apollo 11 insignia\n",
      "The Apollo 11 mission emblem was designed by Collins, who\n",
      "wanted a symbol for \"peaceful lunar landing by the United States\".\n",
      "At Lovell's suggestion, he chose the bald eagle, the national bird of\n",
      "the United States, as the symbol. Tom Wilson, a simulator\n",
      "instructor, suggested an olive branch in its beak to represent their\n",
      "peaceful mission. Collins added a lunar background with the Earth\n",
      "in the distance. The sunlight in the image was coming from the\n",
      "wrong direction; the shadow should have been in the lower part of\n",
      "the Earth instead of the left. Aldrin, Armstrong and Collins\n",
      "decided the Eagle and the Moon would be in their natural colors,\n",
      "and decided on a blue and gold border. Armstrong was concerned\n",
      "that \"eleven\" would not be understood by non-English speakers, so\n",
      "they went with \"Apollo 11\",[70] and they decided not to put their\n",
      "names on the patch, so it would \"be representative of everyone\n",
      "who had worked toward a lunar landing\".[71]\n",
      "An illustrator at the Manned Spacecraft Center (MSC) did the artwork, which was then sent off to\n",
      "NASA officials for approval.[70] The design was rejected. Bob Gilruth, the director of the MSC felt the\n",
      "talons of the eagle looked \"too warlike\".[72] After some discussion, the olive branch was moved to the\n",
      "talons.[72] When the Eisenhower dollar coin was released in 1971, the patch design provided the eagle\n",
      "for its reverse side.[73] The design was also used for the smaller Susan B. Anthony dollar unveiled in\n",
      "1979.[74]\n",
      "After the crew of Apollo 10 named their spacecraft Charlie Brown and Snoopy, assistant manager for\n",
      "public affairs Julian Scheer wrote to George Low, the Manager of the Apollo Spacecraft Program\n",
      "Apollo 11 insignia\n",
      "The Apollo 11 mission emblem was designed by Collins, who\n",
      "wanted a symbol for \"peaceful lunar landing by the United States\".\n",
      "At Lovell's suggestion, he chose the bald eagle, the national bird of\n",
      "the United States, as the symbol. Tom Wilson, a simulator\n",
      "instructor, suggested an olive branch in its beak to represent their\n",
      "peaceful mission. Collins added a lunar background with the Earth\n",
      "in the distance. The sunlight in the image was coming from the\n",
      "wrong direction; the shadow should have been in the lower part of\n",
      "the Earth instead of the left. Aldrin, Armstrong and Collins\n",
      "decided the Eagle and the Moon would be in their natural colors,\n",
      "and decided on a blue and gold border. Armstrong was concerned\n",
      "that \"eleven\" would not be understood by non-English speakers, so\n",
      "they went with \"Apollo 11\",[70] and they decided not to put their\n",
      "names on the patch, so it would \"be representative of everyone\n",
      "who had worked toward a lunar landing\".[71]\n",
      "An illustrator at the Manned Spacecraft Center (MSC) did the artwork, which was then sent off to\n",
      "NASA officials for approval.[70] The design was rejected. Bob Gilruth, the director of the MSC felt the\n",
      "talons of the eagle looked \"too warlike\".[72] After some discussion, the olive branch was moved to the\n",
      "talons.[72] When the Eisenhower dollar coin was released in 1971, the patch design provided the eagle\n",
      "for its reverse side.[73] The design was also used for the smaller Susan B. Anthony dollar unveiled in\n",
      "1979.[74]\n",
      "After the crew of Apollo 10 named their spacecraft Charlie Brown and Snoopy, assistant manager for\n",
      "public affairs Julian Scheer wrote to George Low, the Manager of the Apollo Spacecraft Program\n",
      "<IMG src=extracted_images_2/page_3_img_1.png>The image presents a circular emblem featuring the Apollo 11 mission logo, accompanied by a small section of text at the bottom.\n",
      "\n",
      "*   **Emblem:**\n",
      "    *   The emblem is centered in the image and features a black background with a thin blue border.\n",
      "    *   At the top of the emblem, the words \"APOLLO 11\" are written in gold letters.\n",
      "    *   Below the text, an illustration of an eagle grasping a branch in its talons is depicted.\n",
      "    *   The eagle's head is turned to the right, and its wings are spread outwards.\n",
      "    *   In the background, a small portion of the Earth is visible above the eagle's wing.\n",
      "*   **Text Section:**\n",
      "    *   Below the emblem, there is a small section of text that reads \"JULY 1969\" in black letters.\n",
      "    *   The text is positioned at the bottom center of the image.\n",
      "\n",
      "In summary, the image showcases the Apollo 11 mission logo, which features an eagle and the words \"APOLLO 11\" in gold letters. The logo is surrounded by a blue border and set against a black background, with a small portion of the Earth visible above the eagle's wing. Below the emblem, there is a text section that reads \"JULY 1969\".<IMG>\n",
      "<IMG src=extracted_images_2/page_3_img_1.png>The image presents a circular emblem featuring the Apollo 11 mission logo, accompanied by a small section of text at the bottom.\n",
      "\n",
      "*   **Emblem:**\n",
      "    *   The emblem is centered in the image and features a black background with a thin blue border.\n",
      "    *   At the top of the emblem, the words \"APOLLO 11\" are written in gold letters.\n",
      "    *   Below the text, an illustration of an eagle grasping a branch in its talons is depicted.\n",
      "    *   The eagle's head is turned to the right, and its wings are spread outwards.\n",
      "    *   In the background, a small portion of the Earth is visible above the eagle's wing.\n",
      "*   **Text Section:**\n",
      "    *   Below the emblem, there is a small section of text that reads \"JULY 1969\" in black letters.\n",
      "    *   The text is positioned at the bottom center of the image.\n",
      "\n",
      "In summary, the image showcases the Apollo 11 mission logo, which features an eagle and the words \"APOLLO 11\" in gold letters. The logo is surrounded by a blue border and set against a black background, with a small portion of the Earth visible above the eagle's wing. Below the emblem, there is a text section that reads \"JULY 1969\".<IMG>\n",
      "Contains images in the context True\n",
      "\n",
      "\n",
      "\n",
      "Answer:\n",
      " The symbol of Apollo 11 is an emblem featuring a bald eagle grasping an olive branch in its talons, set against a black background with a thin blue border. The words \"APOLLO 11\" are written in gold letters at the top of the emblem. In the background, a small portion of the Earth is visible above the eagle's wing.\n",
      "Query processed in 9.07 seconds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = input(\"Enter your question\")\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Processing query...\")\n",
    "\n",
    "answer = generate_answer(query)\n",
    "\n",
    "print(\"\\n\\n\\nAnswer:\\n\", answer)\n",
    "\n",
    "print(f\"Query processed in {time.time() - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multimodal Embeddings stored in a single vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/snehithad/anaconda3/envs/AIProject/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('clip-ViT-B-32')\n",
    "processor = SentenceTransformer('clip-ViT-B-32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIPModel.from_pretrained(\"laion/CLIP-ViT-H-14-laion2B-s32B-b79K\")\n",
    "processor = CLIPProcessor.from_pretrained(\"laion/CLIP-ViT-H-14-laion2B-s32B-b79K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_with_clip(image, text):\n",
    "    inputs = processor(text=text, images=image, return_tensors=\"pt\", padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    image_embeds = outputs.image_embeds\n",
    "    # text_embeds = outputs.text_embeds\n",
    "    return image_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_collection(collection_name):\n",
    "    q_client.create_collection(\n",
    "        collection_name,\n",
    "        vectors_config={\n",
    "        \"text_embedding\": models.VectorParams(\n",
    "                size=384,  # Dimension of text embeddings\n",
    "                distance=models.Distance.COSINE,  # Cosine similarity is used for comparison\n",
    "            ),\n",
    "        'image_embedding': models.VectorParams(\n",
    "            size = 512,\n",
    "            distance=models.Distance.COSINE,\n",
    "        ),\n",
    "        },\n",
    "    )\n",
    "\n",
    "create_collection(\"image_text_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_data(points):\n",
    "    operation_info = q_client.upsert(\n",
    "        collection_name=\"image_text_collection\",\n",
    "        points=points,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "docs_list = [Document(page_content=text['response'], metadata={\"name\": text['name']}) for text in text_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectore_store_text = Qdrant(\n",
    "    client = q_client,\n",
    "    collection_name=\"image_text_collection\",\n",
    "    embeddings=embedding_model,\n",
    "    vector_name=\"text_embedding\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnexpectedResponse",
     "evalue": "Unexpected Response: 400 (Bad Request)\nRaw response content:\nb'{\"status\":{\"error\":\"Wrong input: Vector dimension error: expected dim: 1536, got 384\"},\"time\":0.047737625}'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedResponse\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter\u001b[38;5;241m.\u001b[39mfrom_tiktoken_encoder(\n\u001b[1;32m      2\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      5\u001b[0m doc_splits \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_documents(docs_list)\n\u001b[0;32m----> 6\u001b[0m vectore_store_text\u001b[38;5;241m.\u001b[39madd_documents(doc_splits)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/vectorstores/base.py:287\u001b[0m, in \u001b[0;36mVectorStore.add_documents\u001b[0;34m(self, documents, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    286\u001b[0m     metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_texts(texts, metadatas, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    288\u001b[0m msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`add_documents` and `add_texts` has not been implemented \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m )\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_qdrant/vectorstores.py:180\u001b[0m, in \u001b[0;36mQdrant.add_texts\u001b[0;34m(self, texts, metadatas, ids, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m added_ids \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_ids, points \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_rest_batches(\n\u001b[1;32m    178\u001b[0m     texts, metadatas, ids, batch_size\n\u001b[1;32m    179\u001b[0m ):\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mupsert(\n\u001b[1;32m    181\u001b[0m         collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollection_name, points\u001b[38;5;241m=\u001b[39mpoints, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    182\u001b[0m     )\n\u001b[1;32m    183\u001b[0m     added_ids\u001b[38;5;241m.\u001b[39mextend(batch_ids)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m added_ids\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/qdrant_client/qdrant_client.py:1567\u001b[0m, in \u001b[0;36mQdrantClient.upsert\u001b[0;34m(self, collection_name, points, wait, ordering, shard_key_selector, **kwargs)\u001b[0m\n\u001b[1;32m   1564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m         points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_models(points, is_query\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1567\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mupsert(\n\u001b[1;32m   1568\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[1;32m   1569\u001b[0m     points\u001b[38;5;241m=\u001b[39mpoints,\n\u001b[1;32m   1570\u001b[0m     wait\u001b[38;5;241m=\u001b[39mwait,\n\u001b[1;32m   1571\u001b[0m     ordering\u001b[38;5;241m=\u001b[39mordering,\n\u001b[1;32m   1572\u001b[0m     shard_key_selector\u001b[38;5;241m=\u001b[39mshard_key_selector,\n\u001b[1;32m   1573\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1574\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/qdrant_client/qdrant_remote.py:1908\u001b[0m, in \u001b[0;36mQdrantRemote.upsert\u001b[0;34m(self, collection_name, points, wait, ordering, shard_key_selector, **kwargs)\u001b[0m\n\u001b[1;32m   1905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(points, models\u001b[38;5;241m.\u001b[39mBatch):\n\u001b[1;32m   1906\u001b[0m     points \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mPointsBatch(batch\u001b[38;5;241m=\u001b[39mpoints, shard_key\u001b[38;5;241m=\u001b[39mshard_key_selector)\n\u001b[0;32m-> 1908\u001b[0m http_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenapi_client\u001b[38;5;241m.\u001b[39mpoints_api\u001b[38;5;241m.\u001b[39mupsert_points(\n\u001b[1;32m   1909\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[1;32m   1910\u001b[0m     wait\u001b[38;5;241m=\u001b[39mwait,\n\u001b[1;32m   1911\u001b[0m     point_insert_operations\u001b[38;5;241m=\u001b[39mpoints,\n\u001b[1;32m   1912\u001b[0m     ordering\u001b[38;5;241m=\u001b[39mordering,\n\u001b[1;32m   1913\u001b[0m )\u001b[38;5;241m.\u001b[39mresult\n\u001b[1;32m   1914\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m http_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpsert returned None result\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m http_result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/qdrant_client/http/api/points_api.py:987\u001b[0m, in \u001b[0;36mSyncPointsApi.upsert_points\u001b[0;34m(self, collection_name, wait, ordering, point_insert_operations)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupsert_points\u001b[39m(\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    979\u001b[0m     collection_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    982\u001b[0m     point_insert_operations: m\u001b[38;5;241m.\u001b[39mPointInsertOperations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    983\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m m\u001b[38;5;241m.\u001b[39mInlineResponse2006:\n\u001b[1;32m    984\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;124;03m    Perform insert + updates on points. If point with given ID already exists - it will be overwritten.\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 987\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_for_upsert_points(\n\u001b[1;32m    988\u001b[0m         collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[1;32m    989\u001b[0m         wait\u001b[38;5;241m=\u001b[39mwait,\n\u001b[1;32m    990\u001b[0m         ordering\u001b[38;5;241m=\u001b[39mordering,\n\u001b[1;32m    991\u001b[0m         point_insert_operations\u001b[38;5;241m=\u001b[39mpoint_insert_operations,\n\u001b[1;32m    992\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/qdrant_client/http/api/points_api.py:512\u001b[0m, in \u001b[0;36m_PointsApi._build_for_upsert_points\u001b[0;34m(self, collection_name, wait, ordering, point_insert_operations)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m headers:\n\u001b[1;32m    511\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_client\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    513\u001b[0m     type_\u001b[38;5;241m=\u001b[39mm\u001b[38;5;241m.\u001b[39mInlineResponse2006,\n\u001b[1;32m    514\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    515\u001b[0m     url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/collections/\u001b[39m\u001b[38;5;132;01m{collection_name}\u001b[39;00m\u001b[38;5;124m/points\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    516\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders \u001b[38;5;28;01mif\u001b[39;00m headers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    517\u001b[0m     path_params\u001b[38;5;241m=\u001b[39mpath_params,\n\u001b[1;32m    518\u001b[0m     params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[1;32m    519\u001b[0m     content\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    520\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/qdrant_client/http/api_client.py:89\u001b[0m, in \u001b[0;36mApiClient.request\u001b[0;34m(self, type_, method, url, path_params, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     88\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mbuild_request(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(request, type_)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/qdrant_client/http/api_client.py:112\u001b[0m, in \u001b[0;36mApiClient.send\u001b[0;34m(self, request, type_)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ResponseHandlingException(e)\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedResponse\u001b[38;5;241m.\u001b[39mfor_response(response)\n",
      "\u001b[0;31mUnexpectedResponse\u001b[0m: Unexpected Response: 400 (Bad Request)\nRaw response content:\nb'{\"status\":{\"error\":\"Wrong input: Vector dimension error: expected dim: 1536, got 384\"},\"time\":0.047737625}'"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=400, chunk_overlap=50\n",
    ")\n",
    "\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "vectore_store_text.add_documents(doc_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image page_24_img_2.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_21_img_1.png: name 'embed_with_clip' is not defined\n",
      "Error processing image page_29_img_2.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_10_img_1.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_27_img_1.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_9_img_1.png: name 'embed_with_clip' is not defined\n",
      "Error processing image page_22_img_1.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_15_img_1.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_29_img_3.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_16_img_2.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_18_img_1.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_28_img_1.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_25_img_1.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_15_img_2.png: name 'embed_with_clip' is not defined\n",
      "Error processing image page_12_img_1.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_3_img_2.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_3_img_1.png: name 'embed_with_clip' is not defined\n",
      "Error processing image page_10_img_8.png: name 'embed_with_clip' is not defined\n",
      "Error processing image page_8_img_1.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_20_img_1.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_19_img_2.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_5_img_1.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_31_img_1.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_10_img_7.png: name 'embed_with_clip' is not defined\n",
      "Error processing image page_10_img_6.png: name 'embed_with_clip' is not defined\n",
      "Error processing image page_23_img_1.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_14_img_1.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_16_img_1.png: name 'embed_with_clip' is not defined\n",
      "Error processing image page_10_img_4.png: name 'embed_with_clip' is not defined\n",
      "Error processing image page_10_img_5.png: name 'embed_with_clip' is not defined\n",
      "Error processing image page_19_img_1.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_26_img_1.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_17_img_1.png: name 'embed_with_clip' is not defined\n",
      "Error processing image page_10_img_3.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_17_img_2.png: name 'embed_with_clip' is not defined\n",
      "Error processing image page_30_img_1.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_29_img_1.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_1_img_1.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_10_img_2.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_24_img_1.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_13_img_1.jpeg: name 'embed_with_clip' is not defined\n",
      "Error processing image page_1_img_2.png: name 'embed_with_clip' is not defined\n"
     ]
    }
   ],
   "source": [
    "image_splits = []\n",
    "\n",
    "for img in os.listdir(\"extracted_images\"):\n",
    "    try:\n",
    "        image = Image.open(f\"extracted_images/{img}\")\n",
    "        image_embedding = embed_with_clip(image, \"Describe the image content\")\n",
    "        \n",
    "        image_splits.append({\n",
    "            \"id\": img,\n",
    "            \"vector\": image_embedding.detach().numpy()[0],\n",
    "            \"payload\": {\"name\": img}\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {img}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_image = Qdrant(\n",
    "    client=q_client,\n",
    "    collection_name=\"image_text_collection\",\n",
    "    embeddings=CLIPModel,  # No embeddings for the image, using custom embedding function\n",
    "    vector_name=\"image_embedding\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Convert each dictionary into a Document.\n",
    "docs = [\n",
    "    Document(page_content=\"\", metadata=img_dict)\n",
    "    for img_dict in image_splits\n",
    "]\n",
    "\n",
    "vector_store_image.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_image.add_documents(image_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union, Tuple\n",
    "import base64\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_paths(directory: str, number: int = None) -> List[str]:\n",
    "    image_paths = []\n",
    "    count = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.jpeg'):\n",
    "            image_paths.append(os.path.join(directory, filename))\n",
    "            if number is not None and count == number:\n",
    "                return [image_paths[-1]]\n",
    "            count += 1\n",
    "    return image_paths\n",
    "direc = 'extracted_images/'\n",
    "image_paths = get_image_paths(direc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_from_image_path(image_paths):\n",
    "  images = [processor(Image.open(image_path).convert(\"RGB\")) for image_path in image_paths]\n",
    "  image_input = torch.tensor(np.stack(images))\n",
    "  with torch.no_grad():\n",
    "    image_features = model.encode_image(image_input).float()\n",
    "  return image_features\n",
    "image_features = get_features_from_image_path(image_paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
